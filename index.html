<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>reveal.js â€“ The HTML Presentation Framework</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>The Radiant nodes on Iceberg</h1>
				</section>

				<section>
					<h1>Documentation</h1>
					<ul>
            <li>New documentation <a href="http://iceberg.readthedocs.org/en/latest/index.html">http://iceberg.readthedocs.org/en/latest/index.html</a>
						<li>Documentation source <a href="https://github.com/rcgsheffield/iceberg_software">https://github.com/rcgsheffield/iceberg_software</a>
						<li>Old documentation <a href="https://www.shef.ac.uk/wrgrid/iceberg">https://www.shef.ac.uk/wrgrid/iceberg</a>
					</ul>
				</section>

				<section>
					<h3>What do we have?</h3>
					<ul>
						<li>2 Dedicated nodes with 64Gb RAM each</li>

						<li>32 CPU cores total
							<ul>
								<li>16 cores per node
									<li>2 x 8 core Intel Xeon CPU E5-2650 v2 @ 2.60GHz
							</ul>

							<li>4 GPUs total</li>
							<ul>
								<li>2 GPUs per node
								<li>NVIDIA K40M - 2880 CUDA Cores, 12 GB each
							</ul>
			       <li>2 Tb Dedicated, backed-up storage </li>
						 <li>Until 12/10/2017</li>
					</ul>
				</section>

				<section>
        <h1>All of Iceberg</h1>
				<ul>
					<li>Total CPUs: 3440 cores
					<li>Total GPUs: 16 units
					<li>Total Memory: 31.8 TBytes
					<li>Permanent Filestore: 45 TBytes
					<li>Temporary Filestore: 260 TBytes
        </ul>

				</section>

				<section>
					<h3>Log in</h3>
					<p>Gets you to a log-in node</p>
					<pre>
						<code>
ssh -X username@iceberg.sheffield.ac.uk
						</code>
					</pre>
					<p>As soon as you log in, get an interactive session on a worker node.</p>
					<p>You can't do much on the log-in nodes.</p>
				</section>

				<section>
					<h3>Interactive access</h3>
					<p>Gets you on a worker node. Makes software available.</p>
					<p>From the log-in node:</p>
          <pre>
					<code>
qsh                          #Xterm session (Not great!)
qrsh                         #Text only terminal
qrsh -v DISPLAY -pty y bash  #Terminal with X windows support
                             #(RECOMMENDED)
					</code>
				</pre>
					<p>The <code>qsh</code> graphical terminal is very old and limited.
						Only use it if you really have to.</p>
				</section>

				<section>
					<h3>Interactive access - which nodes?</h3>
					<pre>
					<code>
#Interactive access on any node
qrsh

#Any node but prefer ours
qrsh -P radiant

#Only use our nodes. Only do this when necessary.
qrsh -P radiant -q radiant.q
					</code>
				</pre>
				</section>

				<section>
					<p>Batch jobs (submit and go)</p>
					<p>Recommended way to use Iceberg</p>
				</section>

				<section>
					<p>Submission script</p>
					<pre>
#!/bin/bash
# Submission scripts are bash scripts
# Request 5 gigabytes of real memory (mem)
# and 5 gigabytes of virtual memory (mem)
#$ -l mem=5G -l rmem=5G

# load the module for the program we want to run
module load apps/gcc/foo

#Run the program foo with input foo.dat
#and output foo.res
foo < foo.dat > foo.res
					</pre>
				</section>

				<section>
					<p> Submit with qsub</p>
					<pre>qsub myscript.sh</pre>
					<p> Get status with qstat </p>
					<pre>qstat -u USERNAME</pre>
			</section>

				<section>
					<p>Submit and Status- Example</p>
<pre><code>[foo123@node067 R_parallel]$ qsub parallel_kmeans.sge
Your job 945292 ("parallel_kmeans.sge") has been submitted



[foo123@node067 R_parallel]$ qstat -u foo123
job-ID  prior   name       user         state submit/start at     queue                          slots ja-task-ID
-----------------------------------------------------------------------------------------------------------------
 945288 0.00050 QRLOGIN    foo123       r     02/19/2016 12:09:48 interactive.q@node067.iceberg.     1
 945292 0.00000 parallel_k foo123       qw    02/19/2016 12:10:46                                    4
</code>
 </pre>
</section>
<section>
	<p>Delete a job with qdel</p>
	<pre><code>qdel job-ID  #general form</code></pre>
	<pre><code>qdel 945292  #Specific example</code></pre>
</section>
				<section>
					<p>How busy are our nodes?</p>
					<pre><code>qstat -q radiant.q</code></pre>
				</section>

				<section>
					Historic usage can be seen from the accounting file /usr/local/sge/live/default/common/accounting - it's big and infrequently rotated, so processing can be a pain.  qacct can be used to provide a summary of usage for a given project, and the man pages are fairly helpful.

Ganglia can also be used to see graphs of how well a node is coping with a particular job - node215 & node216 for radiant.q
http://gridweb1.shef.ac.uk/ganglia/?m=load_one&r=hour&s=by%2520name&c=iceberg&h=&sh=1&hc=6&z=small
				</section>

				<section>
					<h3>Genral Storage</h3>
					<p>Everyone in the University has</p>
					<p><pre>/home/USERNAME - 10Gb</pre></p>
					<p><pre>/data/USERNAME - 100Gb</pre></p>
					<p><pre>/fastdata/USERNAME - 'Unlimited'</pre></p>
						<p>Different backup policies, rules etc. Details at the <a href="http://iceberg.readthedocs.org/en/latest/using-iceberg/filestore.html">documentation</a></p>
				</section>

				<section>
					<h3>Our extra storage</h3>
					<p>Just for us. We have 2 Terabytes</p>
					<p><pre>/shared/radiant2/shared/ - Everyone in the group can see it</pre></p>
					<p><pre>/shared/radiant2/user/ - Private folders for each of us</pre></p>
				</section>

				<section>
					<h3>Mounting Storage Locally</h3>
					<p>Create a directory on your machine</p<>
						<pre><code>mkdir /media/iceberg/</code></pre></p>
					Add the following to your /etc/fstab file
					<pre><code>//uosfstore.shef.ac.uk/shared/radiant2	/media/iceberg/	cifs	username=youruser,iocharset=utf8  0  0</code></pre>
					<p>Mount with <pre><code>sudo mount /media/iceberg/</code></pre></p>


				</section>


			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
